from datetime import datetime
import logging
from db_configs import mongo_back as mongos  # åˆ‡æ¢é…ç½®åªéœ€æ”¹è¿™é‡Œçš„åå­—


# ======================
# é…ç½®é¡¹
# ======================
DB_NAME = 'electric_bicycle'
COLLECTION_NAME = 'order'

# æ—¥å¿—é…ç½®ï¼ˆå¯é€‰ï¼Œä¾¿äºæ’æŸ¥é—®é¢˜ï¼‰
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'order_query_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ======================
# æ ¸å¿ƒæŸ¥è¯¢å‡½æ•°
# ======================
def connect_mongodb():
    """è¿æ¥MongoDBï¼ˆæ²¿ç”¨mongosæ¨¡å—çš„è¿æ¥æ–¹å¼ï¼‰"""
    try:
        db = mongos.mongo_connect()
        collection = db[DB_NAME][COLLECTION_NAME]
        # éªŒè¯è¿æ¥
        collection.count_documents({}, limit=1)
        logger.info("âœ… MongoDBè¿æ¥æˆåŠŸï¼ˆä½¿ç”¨mongosæ¨¡å—ï¼‰")
        return collection
    except Exception as e:
        logger.error(f"âŒ MongoDBè¿æ¥å¤±è´¥ï¼š{str(e)}", exc_info=True)
        raise

def query_orders_by_aggregate():
    """æ‰§è¡ŒèšåˆæŸ¥è¯¢ï¼Œè¿˜åŸMongoDB Shellçš„èšåˆé€»è¾‘"""
    try:
        # 1. è¿æ¥æ•°æ®åº“
        collection = connect_mongodb()

        # 2. å®šä¹‰èšåˆç®¡é“ï¼ˆå®Œå…¨è¿˜åŸä½ çš„Shellèšåˆé€»è¾‘ï¼‰
        pipeline = [
            # æ­¥éª¤1ï¼šè¿‡æ»¤ç¬¦åˆæ¡ä»¶çš„è®¢å•
            {
                "$match": {
                    "preEntryStatus": "COMPLETED",  # ä¸Šç‰Œå®Œæˆ
                    "state": 1,  # å·²éªŒè¯ï¼ˆæœ‰æ•ˆï¼‰
                    "buyer.idType": 2,  # ä¹°å®¶IDç±»å‹ä¸º2
                    "cancelled": False,  # æœªå–æ¶ˆ
                    "createdDate": {"$lte": datetime.fromisoformat("2025-12-04T15:59:00+00:00")},  # æˆªæ­¢æ—¶é—´ï¼ˆUTCï¼‰
                    "userId": "69211df3f5a10065b74b43ae"  # ç›®æ ‡ç”¨æˆ·ID
                }
            },
            # æ­¥éª¤2ï¼šè½¬æ¢userCountyä¸ºåŒºåŸŸä¸­æ–‡åç§°
            {
                "$addFields": {
                    "åŒºåŸŸä¸­æ–‡åç§°": {
                        "$switch": {
                            "branches": [
                                {"case": {"$eq": ["$userCounty", "330198"]}, "then": "æµ™æ±Ÿçœæ­å·å¸‚æ­å·ä¸»åŸåŒº"},
                                {"case": {"$eq": ["$userCounty", "330189"]}, "then": "æµ™æ±Ÿçœæ­å·å¸‚æ­å·æ¡åºå¿"},
                                {"case": {"$eq": ["$userCounty", "330190"]}, "then": "æµ™æ±Ÿçœæ­å·å¸‚æ­å·æ·³å®‰å¿"},
                                {"case": {"$eq": ["$userCounty", "330191"]}, "then": "æµ™æ±Ÿçœæ­å·å¸‚æ­å·å¯Œé˜³åŒº"},
                                {"case": {"$eq": ["$userCounty", "330192"]}, "then": "æµ™æ±Ÿçœæ­å·å¸‚æ­å·è§å±±åŒº"},
                                {"case": {"$eq": ["$userCounty", "330193"]}, "then": "æµ™æ±Ÿçœæ­å·å¸‚æ­å·å»ºå¾·åŒº"},
                                {"case": {"$eq": ["$userCounty", "330194"]}, "then": "æµ™æ±Ÿçœæ­å·å¸‚æ­å·ä¸´å®‰åŒº"},
                                {"case": {"$eq": ["$userCounty", "330195"]}, "then": "æµ™æ±Ÿçœæ­å·å¸‚æ­å·ä¸´å¹³åŒº"},
                                {"case": {"$eq": ["$userCounty", "330196"]}, "then": "æµ™æ±Ÿçœæ­å·å¸‚æ­å·é’±å¡˜åŒº"},
                                {"case": {"$eq": ["$userCounty", "330197"]}, "then": "æµ™æ±Ÿçœæ­å·å¸‚æ­å·ä½™æ­åŒº"}
                            ],
                            "default": "æœªçŸ¥åŒºåŸŸ"
                        }
                    }
                }
            },
            # æ­¥éª¤3ï¼šæ ¼å¼åŒ–è¾“å‡ºå­—æ®µï¼ˆåªä¿ç•™3ä¸ªç›®æ ‡å­—æ®µï¼‰
            {
                "$project": {
                    "_id": 0,  # éšè—é»˜è®¤_id
                    "åŒºåŸŸä¸­æ–‡åç§°": 1,
                    "è½¦æ¶å·": "$frameNumber",
                    "å·ç‰Œ": "$numberPlate"
                }
            },
            # æ­¥éª¤4ï¼šæŒ‰åŒºåŸŸåç§°å‡åºæ’åº
            {
                "$sort": {"åŒºåŸŸä¸­æ–‡åç§°": 1}
            }
        ]

        # 3. æ‰§è¡ŒèšåˆæŸ¥è¯¢
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡ŒèšåˆæŸ¥è¯¢...")
        result = list(collection.aggregate(pipeline))  # è½¬æ¢ä¸ºåˆ—è¡¨ä¾¿äºå¤„ç†

        # 4. è¾“å‡ºæŸ¥è¯¢ç»“æœ
        logger.info(f"âœ… æŸ¥è¯¢å®Œæˆï¼Œå…±åŒ¹é…åˆ° {len(result)} æ¡æ•°æ®")
        print(f"\nğŸ“Š æŸ¥è¯¢ç»“æœæ±‡æ€»ï¼šå…±åŒ¹é…åˆ° {len(result)} æ¡æ•°æ®")
        print("=" * 80)
        
        # æ‰“å°æ¯æ¡ç»“æœï¼ˆæ ¼å¼åŒ–è¾“å‡ºï¼‰
        for idx, item in enumerate(result, 1):
            print(f"[{idx}] åŒºåŸŸï¼š{item.get('åŒºåŸŸä¸­æ–‡åç§°', 'æœªçŸ¥åŒºåŸŸ')} | è½¦æ¶å·ï¼š{item.get('è½¦æ¶å·', '-')} | å·ç‰Œï¼š{item.get('å·ç‰Œ', '-')}")
        
        return result

    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼š{str(e)}", exc_info=True)
        print(f"\nâŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
        raise

# ======================
# ä¸»å‡½æ•°
# ======================
def main():
    print("=" * 80)
    print("ğŸ“‹ å¼€å§‹æ‰§è¡Œè®¢å•èšåˆæŸ¥è¯¢è„šæœ¬")
    print(f"ğŸ” æŸ¥è¯¢æ¡ä»¶ï¼šuserId=69211df3f5a10065b74b43aeï¼Œä¸Šç‰Œå®Œæˆï¼Œæˆªæ­¢æ—¶é—´2025-12-04 15:59")
    print("=" * 80)
    
    # æ‰§è¡ŒæŸ¥è¯¢
    query_result = query_orders_by_aggregate()
    
    # å¯é€‰ï¼šå°†ç»“æœä¿å­˜ä¸ºCSVæ–‡ä»¶
    save_to_csv = input("\nğŸ“Œ æ˜¯å¦å°†æŸ¥è¯¢ç»“æœä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼Ÿ(y/n)ï¼š").strip()
    if save_to_csv.lower() == 'y':
        csv_path = f"order_query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        try:
            import csv
            with open(csv_path, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=["åŒºåŸŸä¸­æ–‡åç§°", "è½¦æ¶å·", "å·ç‰Œ"])
                writer.writeheader()
                writer.writerows(query_result)
            logger.info(f"ğŸ“ æŸ¥è¯¢ç»“æœå·²ä¿å­˜åˆ°ï¼š{csv_path}")
            print(f"\nâœ… æŸ¥è¯¢ç»“æœå·²ä¿å­˜åˆ°ï¼š{csv_path}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜CSVå¤±è´¥ï¼š{str(e)}", exc_info=True)
            print(f"\nâŒ ä¿å­˜CSVå¤±è´¥ï¼š{str(e)}")

    print("\nğŸ‰ è„šæœ¬æ‰§è¡Œå®Œæ¯•ï¼")

# ======================
# ç¨‹åºå…¥å£
# ======================
if __name__ == "__main__":
    main()